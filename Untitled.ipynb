{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "import time\n",
    "import importlib\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from network.net import net_option\n",
    "from utils.logger import MyLog\n",
    "from utils.core_utils import count_parameters\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as  plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Global Parameter\n",
    "######################################\n",
    "softmax = torch.nn.Softmax(dim = 1)\n",
    "SHOW_SEG_RESULT = True\n",
    "confidence_threshold = 0.7\n",
    "DEBUG_MIN_OBJ_WIDTH = True\n",
    "wmin = 100\n",
    "\n",
    "pick_interval = 8\n",
    "min_distance_threshold = 50\n",
    "min_angle_threshold = 60\n",
    "\n",
    "\n",
    "\n",
    "LINE_WIDTH = 2\n",
    "\n",
    "color_polate_4cls = {1: \"#00FF00\",\n",
    "                     2: \"#0000FF\",\n",
    "                     3: \"#FFFF00\",\n",
    "                     4: \"#00FFFF\",\n",
    "                     5: \"#FF0000\"}\n",
    "\n",
    "color_polate_4cls_QT = {3: \"FF0\",\n",
    "                        4: \"0FF\",\n",
    "                        5: \"F00\"}\n",
    "\n",
    "\n",
    "cmap_4cls = {1: (  0,255,  0),\n",
    "             2: (  0,  0,255),\n",
    "             3: (255,255,  0),\n",
    "             4: (  0,255,255),\n",
    "             5: (255,  0,  0)}\n",
    "alpha = 0.5\n",
    "\n",
    "\n",
    "INPUT_SHAPE = (256,512 ,3) #row col\n",
    "\n",
    "\n",
    "\n",
    "model_type = 'Jacinto_256x512_v3'\n",
    "model_check_point = 'weights/detseg_ivs_revise_ssd_anchor/Jacinto_256x512_v3_256x512_detection_v1_ivs_bs_16_lr_1e-05_fixbackbone_True_freeze_bn_True_sampler_False_focaloss_True_revise_anchor_499.pt'\n",
    "od_threshold = 0.3\n",
    "######################################\n",
    "# Global Parameter\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-m\", dest = \"model\", type = str, help = \"Network archtecture.\")\n",
    "    parser.add_argument(\"-i\", dest = \"input_size\", type = int, nargs = \"+\", default = [256,512], help = \"Network input size.\")\n",
    "    parser.add_argument(\"-c\", dest = \"checkpoint\", type = str, help = \"Checkpoint file.\")\n",
    "    parser.add_argument(\"-iv\", dest = \"input_video\", type = str, required = True, help = \"Input video for demo.\")\n",
    "    parser.add_argument(\"-ot\", dest = \"od_threshold\",  type = float, default = 0.3, help = \"Detection Confidence threshold.\")\n",
    "    parser.add_argument(\"-ov\", dest = \"output_video\", action = \"store_true\", help = \"Input video for demo.\")\n",
    "    parser.add_argument(\"-camera\", dest = \"camera\", action = \"store_true\", help = \"Input video for demo.\")\n",
    "    return parser.parse_args()\n",
    "# args = get_arguments()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Global Parameter\n",
    "######################################\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "net = net_option(model_type, mode = \"end2end\")\n",
    "net = net.to(device)\n",
    "\n",
    "# resume from checkpoint\n",
    "assert os.path.exists(model_check_point), \"Checkpoint {} does not exist.\".format(model_check_point)\n",
    "state = torch.load(model_check_point)\n",
    "net.load_state_dict(state[\"model_state\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_back(pred, size):\n",
    "    \"\"\" \n",
    "    upsmaple back if segmentation pred if its size not equal to \"size\"\n",
    "    Args:\n",
    "       (1) pred: numpy array with size (H',W')\n",
    "       (2) size: tuple (H,W)\n",
    "    Return:\n",
    "       (1) pred: numpy array with size (H',W')\n",
    "    \"\"\"\n",
    "    if pred.shape != size:\n",
    "        pred = cv2.resize(pred, (size[1], size[0]), 0, 0, interpolation = cv2.INTER_NEAREST)\n",
    "        return pred\n",
    "    else:\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_post_process_find_mid(pred_seg, prob_map, pred_seg_max, img_draw):\n",
    "    \"\"\"Self define cluster method, try to find the mid points of each row \"\"\"\n",
    "    ###########################\n",
    "    # get local max & cluster #\n",
    "    ###########################\n",
    "    tic = time.time()\n",
    "    y_value = pred_seg.shape[1]-40\n",
    "    # sample point contaion : (x, y, vector, label)\n",
    "    sampled_points_info = []\n",
    "    prob_map[:, 0] = 0.0 \n",
    "    prob_map[:, -1] = 0.0 \n",
    "    while(y_value > 0):\n",
    "        #####################\n",
    "        # get local maximum #\n",
    "        #####################\n",
    "        ticc = time.time()\n",
    "        difference = np.diff(prob_map[y_value])\n",
    "        difference[difference < 0] = -difference[difference < 0]\n",
    "        difference[difference < confidence_threshold-0.1] = 0\n",
    "        where = np.where(difference)\n",
    "        indexes = where[0][1::2] + where[0][::2]\n",
    "        indexes = indexes//2\n",
    "        tocc = time.time()\n",
    "        if indexes.shape == 0:\n",
    "            y_value -= pick_interval\n",
    "            continue\n",
    "        if len(sampled_points_info) == 0:\n",
    "            # for the first point, the angle can only be none\n",
    "            # point: [x, y, angle, label]\n",
    "            sampled_points_info = [[[point_x, y_value, None, pred_seg_max[y_value, point_x]]] for point_x in indexes]\n",
    "            y_value -= pick_interval\n",
    "            continue\n",
    "        ####################\n",
    "        # start clustering #\n",
    "        ####################\n",
    "        for point_x in indexes:\n",
    "            # [distance, direction]\n",
    "            new_info = [[point_distance((cluster[-1][0], cluster[-1][1]), (point_x, y_value)), \\\n",
    "                 point_degree(cluster[-1][2], (point_x - cluster[-1][0], y_value - cluster[-1][1]))] for cluster in sampled_points_info]\n",
    "            new_info = np.array(new_info)\n",
    "            min_distance_index = np.argmin(new_info[:, 0])\n",
    "            min_distance = np.min(new_info[:, 0])\n",
    "            angle = new_info[min_distance_index, 1]\n",
    "            # print(\"angle min_distance\", angle, min_distance)\n",
    "            # if (min_distance < min_distance_threshold):\n",
    "            if (min_distance < min_distance_threshold and angle is None) or\\\n",
    "               (min_distance < min_distance_threshold and angle < min_angle_threshold and angle is not None):\n",
    "                # print(\"add to cluster\")\n",
    "                new_unit_vector = get_unit_vector((point_x, y_value),(sampled_points_info[min_distance_index][-1][0], sampled_points_info[min_distance_index][-1][1]))\n",
    "                if sampled_points_info[min_distance_index][-1][2] is not None:\n",
    "                    average_vector = ((new_unit_vector[0]+sampled_points_info[min_distance_index][-1][2][0])/2,\n",
    "                                    (new_unit_vector[1]+sampled_points_info[min_distance_index][-1][2][1])/2 )\n",
    "                    sampled_points_info[min_distance_index].append([point_x, y_value, average_vector, pred_seg_max[y_value, point_x]])\n",
    "                else:\n",
    "                    sampled_points_info[min_distance_index].append([point_x, y_value, new_unit_vector, pred_seg_max[y_value, point_x]])\n",
    "            else:\n",
    "                sampled_points_info.append([[point_x, y_value, None, pred_seg_max[y_value, point_x]]])\n",
    "        y_value -= pick_interval\n",
    "    toc = time.time()\n",
    "    print(\"Clustering time: {}\".format(toc - tic))\n",
    "    ##########################\n",
    "    # draw clustering result #\n",
    "    ##########################\n",
    "    tic = time.time()\n",
    "    queue_info = [] \n",
    "    for i, cluster in enumerate(sampled_points_info):\n",
    "        cluster = np.array(cluster)\n",
    "        if cluster.shape[0] < 5:\n",
    "            continue\n",
    "        # vote using class label\n",
    "        unique, count = np.unique(cluster[:, -1], return_counts = True)\n",
    "        cluster_class = unique[np.argmax(count)]\n",
    "        if cluster_class == 0:\n",
    "            continue\n",
    "        cluster = cluster[cluster[:,-1] == cluster_class]    \n",
    "        ############\n",
    "        # poly fit #\n",
    "        ############\n",
    "        order = 2\n",
    "        cluster_xy = cluster[:,:2] \n",
    "        cluster_xy = cluster_xy.astype(np.int32)\n",
    "        # judge if use poly fit or not\n",
    "        if cluster_xy[:, 0][0] > cluster_xy[:, 0][-1]:\n",
    "            cluster_xy = cluster_xy[::-1,:]\n",
    "        x_cor_diff = np.diff(cluster_xy[:, 0])\n",
    "        # if True:\n",
    "        if np.where(x_cor_diff < 0)[0].shape[0] == 0:\n",
    "            \"\"\"case to use poly fit\"\"\"\n",
    "            poly_parameter = np.polyfit(cluster_xy[:,0], cluster_xy[:, 1], order)\n",
    "            poly = np.poly1d(poly_parameter)\n",
    "            x, y = cluster_xy[:, 0], poly(cluster_xy[:, 0])\n",
    "            # draw.ax4.plot(cluster_xy[:, 0], poly(cluster_xy[:, 0]), color = color_polate_4cls[cluster_class], linewidth = 2)\n",
    "        else:\n",
    "            poly_parameter = np.polyfit(cluster_xy[:,1], cluster_xy[:, 0], order)\n",
    "            poly = np.poly1d(poly_parameter)\n",
    "            # x, y = cluster_xy[:, 0], poly(cluster_xy[:, 0])\n",
    "            x, y = poly(cluster_xy[:, 1]), cluster_xy[:, 1]\n",
    "            # draw.ax4.plot(cluster_xy[:, 0], cluster_xy[:, 1], color = color_polate_4cls[cluster_class], linewidth = 2)\n",
    "        # if i == 0:\n",
    "        #     ppen = pg.mkPen(color= color_polate_4cls_QT[cluster_class], width= 2)\n",
    "        #     self.curve1.setData(x,y,pen=ppen)\n",
    "        # elif i == 1:\n",
    "        #     ppen = pg.mkPen(color= color_polate_4cls_QT[cluster_class], width= 2)\n",
    "        #     self.curve2.setData(x,y,pen=ppen)\n",
    "        # elif i == 2:\n",
    "        #     ppen = pg.mkPen(color= color_polate_4cls_QT[cluster_class], width= 2)\n",
    "        #     self.curve3.setData(x,y,pen=ppen)\n",
    "        # elif i == 3:\n",
    "        #     ppen = pg.mkPen(color= color_polate_4cls_QT[cluster_class], width= 2)\n",
    "        #     self.curve4.setData(x,y,pen=ppen)\n",
    "        # elif i == 4:\n",
    "        #     ppen = pg.mkPen(color= color_polate_4cls_QT[cluster_class], width= 2)\n",
    "        #     self.curve5.setData(x,y,pen=ppen)\n",
    "        # elif i == 5:\n",
    "        #     ppen = pg.mkPen(color= color_polate_4cls_QT[cluster_class], width= 2)\n",
    "        #     self.curve6.setData(x,y,pen=ppen)\n",
    "        queue_info.append([x, y, cluster_class])\n",
    "        y_value -= pick_interval\n",
    "    toc = time.time()\n",
    "    print(\"DBSCAN time: {}\".format(toc - tic))\n",
    "    queue_info = [img_draw] + queue_info\n",
    "    return queue_info\n",
    "\n",
    "    \n",
    "def point_distance(point1, point2):\n",
    "    # print(point1, point2)\n",
    "    return ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5\n",
    "def point_degree(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Compute angle between two vector\n",
    "    Args:\n",
    "        (1) vector1: vector in the cluster\n",
    "        (2) vector2: new vector obtained from new points and cluster point\n",
    "    Return:\n",
    "        (1) angle: angle between two vector\n",
    "    \"\"\"\n",
    "    if vector1 == None:\n",
    "        return None\n",
    "    # cos = dot(v1,v2)/len(v1, v2)\n",
    "    cos = (vector1[0] * vector2[0] + vector1[1] * vector2[1])/(((vector1[0]**2 + vector1[1]**2)**0.5)*((vector2[0]**2 + vector2[1]**2)**0.5))\n",
    "    if cos >= 1:\n",
    "        cos = 1.0\n",
    "    if cos <= -1:\n",
    "        cos = -1.0\n",
    "    angle = 180*math.acos(cos)/3.14\n",
    "    # print(\"angle\", angle)\n",
    "    return angle\n",
    "\n",
    "def get_unit_vector(point1, point2):\n",
    "    \"\"\"get unit vector from point2 point to point1\n",
    "    Args:\n",
    "    (1) point1: end point \n",
    "    (2) point2: start point\n",
    "    Return:\n",
    "    (1) unit_vector: unit vector from point2 point to point1\n",
    "    \"\"\"\n",
    "    vector_length = ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5\n",
    "    return ((point1[0] - point2[0])/vector_length, (point1[1] - point2[1])/vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Main Process\n",
    "######################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "skip_frame = 1\n",
    "count = 0\n",
    "net.target_available = False\n",
    "net.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    while(cap.isOpened()):\n",
    "        ret,frame = cap.read()\n",
    "        assert frame.shape[0]>0\n",
    "        \n",
    "        # skip until spicific frame\n",
    "        if(count%skip_frame!=0):\n",
    "            count += 1\n",
    "            continue\n",
    "        else:\n",
    "            count +=1\n",
    "        \n",
    "        start = time.time()\n",
    "        RGB = np.zeros(INPUT_SHAPE,dtype=np.uint8)\n",
    "        print(\"-------------------\")\n",
    "        tic = time.time()\n",
    "        \n",
    "        #resize image\n",
    "        img = cv2.resize(frame, (INPUT_SHAPE[1], INPUT_SHAPE[0]), 0, 0, interpolation = cv2.INTER_LINEAR)\n",
    "        #BRG to RGB\n",
    "        img = img[:,:,[2,1,0]]\n",
    "        # transfrom and expand dim\n",
    "        input = img.transpose((2, 0, 1))\n",
    "        input = np.expand_dims(input, axis = 0)\n",
    "        # push to tensor\n",
    "        input = torch.from_numpy(input).float()\n",
    "        input = input.to(device)\n",
    "        toc = time.time()\n",
    "        print(\"Preprocess time: {:.3f}\".format(toc - tic))\n",
    "        # net forward\n",
    "        tic =time.time()\n",
    "        scores, classification, transformed_anchors, pred_seg_t = net(input)\n",
    "        pred_seg = softmax(pred_seg_t)\n",
    "        toc =time.time()\n",
    "        print(\"Net forward time: {}\".format(toc - tic))\n",
    "        tic =time.time()\n",
    "        \n",
    "        # threhold\n",
    "        # pred_seg[pred_seg < confidence_threshold] = 0\n",
    "        # back to cpu\n",
    "        pred_seg = pred_seg.squeeze(dim = 0)\n",
    "        pred_seg = pred_seg.data.cpu().numpy()\n",
    "        pred_seg[pred_seg < confidence_threshold] = 0\n",
    "\n",
    "        img_draw = img.astype(np.uint8)\n",
    "\n",
    "        prob_map = np.max(pred_seg[3:, :, :], axis = 0)\n",
    "\n",
    "        pred_seg_max = np.argmax(pred_seg, axis = 0)\n",
    "        toc =time.time()\n",
    "        print(\"Pre-Post-process time: {}\".format(toc - tic))\n",
    "\n",
    "\n",
    "        tic = time.time()\n",
    "        # upsample back if prediction size not equal to input_size\n",
    "        pred_seg_max_up = upsample_back(pred_seg_max, INPUT_SHAPE)\n",
    "\n",
    "        overlay_flag = np.zeros((INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "        # draw\n",
    "        for key, color in cmap_4cls.items():\n",
    "\n",
    "            if key == 0:\n",
    "                continue\n",
    "            if key >= 3:\n",
    "\n",
    "                continue\n",
    "            else:\n",
    "\n",
    "                RGB[pred_seg_max_up == key] = np.array(color)\n",
    "                overlay_flag[pred_seg_max_up == key] = 1\n",
    "\n",
    "        overlay = cv2.addWeighted(img_draw, alpha, RGB, (1-alpha), 0)\n",
    "\n",
    "        img_draw[overlay_flag == 1] = overlay[overlay_flag == 1]\n",
    "\n",
    "        img_draw_down = img_draw.copy()\n",
    "        \n",
    "\n",
    "        \n",
    "        toc =time.time()\n",
    "        print(\"Segmentation draw time: {}\".format(toc - tic))\n",
    "        \n",
    "        \n",
    "        ##################\n",
    "        # draw detection #\n",
    "        ##################\n",
    "        tic = time.time()\n",
    "        scores = scores.data.cpu().numpy()\n",
    "        idxs = np.where(scores > od_threshold) \n",
    "        for j in range(idxs[0].shape[0]):\n",
    "            class_ =int(classification[idxs[0][j]])\n",
    "            bbox = transformed_anchors[idxs[0][j], :]\n",
    "            x1 = int(round(bbox[0]))\n",
    "            y1 = int(round(bbox[1]))\n",
    "            x2 = int(round(bbox[2]))\n",
    "            y2 = int(round(bbox[3]))\n",
    "            # ped\n",
    "            if class_ == 0 or class_ == 1:\n",
    "                cv2.rectangle(img_draw_down, (x1,y1), (x2, y2), (0,255,0), LINE_WIDTH) \n",
    "            # car\n",
    "            elif class_ == 2 or class_ == 3 or class_ == 4:\n",
    "                cv2.rectangle(img_draw_down, (x1,y1), (x2, y2), (0,0,255), LINE_WIDTH) \n",
    "            # motor\n",
    "            elif class_ == 5 or class_ == 6 or class_ == 7:\n",
    "                cv2.rectangle(img_draw_down, (x1,y1), (x2, y2), (255,0,0),  LINE_WIDTH) \n",
    "            else:\n",
    "                cv2.rectangle(img_draw_down, (x1,y1), (x2, y2), (0,0,0), LINE_WIDTH) \n",
    "        toc = time.time()\n",
    "        print(\"Detection draw took: {}\".format(toc - tic))\n",
    "        a = lane_post_process_find_mid(pred_seg, prob_map, pred_seg_max, img_draw_down)[0]\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"Total time: {}\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
